{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"39f07d2d-091d-4195-8200-f61f9241e2de","_cell_guid":"15b97161-88aa-4e4e-a340-36a978096421","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-08T14:36:47.154628Z","iopub.execute_input":"2025-11-08T14:36:47.155133Z","iopub.status.idle":"2025-11-08T14:36:47.197763Z","shell.execute_reply.started":"2025-11-08T14:36:47.155017Z","shell.execute_reply":"2025-11-08T14:36:47.196369Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport numpy as np, pandas as pd, matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\nfrom sklearn.metrics import make_scorer, roc_auc_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"_uuid":"9f7a3288-955c-4eee-aba1-abe0e0a8870a","_cell_guid":"f2906ef6-e083-43c2-b4f8-1b613a18712f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-08T14:36:47.199961Z","iopub.execute_input":"2025-11-08T14:36:47.200692Z","iopub.status.idle":"2025-11-08T14:36:47.210212Z","shell.execute_reply.started":"2025-11-08T14:36:47.200656Z","shell.execute_reply":"2025-11-08T14:36:47.209356Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/test.csv\")","metadata":{"_uuid":"f7910342-ea6d-422c-869a-eed0506ad6c5","_cell_guid":"e9bf1fa7-82b4-4d4e-b19c-e2667f9957b5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-08T14:36:47.211266Z","iopub.execute_input":"2025-11-08T14:36:47.211526Z","iopub.status.idle":"2025-11-08T14:36:51.215334Z","shell.execute_reply.started":"2025-11-08T14:36:47.211505Z","shell.execute_reply":"2025-11-08T14:36:51.214532Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.head(2)","metadata":{"_uuid":"85bec991-5cb1-41eb-a28f-8b684ad89cc0","_cell_guid":"cd9c9bac-78ae-48d6-888d-beb9afd37d45","trusted":true,"collapsed":false,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2025-11-08T14:36:51.217898Z","iopub.execute_input":"2025-11-08T14:36:51.218305Z","iopub.status.idle":"2025-11-08T14:36:51.242049Z","shell.execute_reply.started":"2025-11-08T14:36:51.218282Z","shell.execute_reply":"2025-11-08T14:36:51.241152Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.head(2)","metadata":{"_uuid":"f22814eb-c235-4274-a2f9-5bb8fdfdfb12","_cell_guid":"0daa0161-564f-4fb1-a591-6d86953fdbfc","trusted":true,"collapsed":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-11-08T14:36:51.242980Z","iopub.execute_input":"2025-11-08T14:36:51.243211Z","iopub.status.idle":"2025-11-08T14:36:51.266380Z","shell.execute_reply.started":"2025-11-08T14:36:51.243194Z","shell.execute_reply":"2025-11-08T14:36:51.265409Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Options\ndrop_ties = True     # set False to include ties\nsample    = 8000   # None to use all rows\n\n# 1) Build text and labels\ntext = (\n    \"[PROMPT] \" + df_train[\"prompt\"].fillna(\"\").astype(str) +\n    \" [ANS_A] \" + df_train[\"response_a\"].fillna(\"\").astype(str) +\n    \" [ANS_B] \" + df_train[\"response_b\"].fillna(\"\").astype(str)\n)\ny = df_train[[\"winner_model_a\",\"winner_model_b\",\"winner_tie\"]].values.argmax(1)\n\n# 2) Filter and subsample\nif drop_ties:\n    m = (y != 2)\n    text, y = text[m], y[m]\nif sample and len(text) > sample:\n    idx = np.random.default_rng(0).choice(len(text), size=sample, replace=False)\n    text, y = text.iloc[idx], y[idx]\n\n# 3) TF-IDF → 2D SVD\nvec = TfidfVectorizer(max_features=20000, ngram_range=(1,2),\n                      stop_words=\"english\", min_df=2, sublinear_tf=True)\nX = vec.fit_transform(text)\nZ = TruncatedSVD(n_components=2, random_state=0).fit_transform(X)\n\n# 4) Scatter plot\ncolors = {0:\"#e74c3c\", 1:\"#3498db\", 2:\"#95a5a6\"}  # A, B, Tie\nlabels = {0:\"A\", 1:\"B\", 2:\"Tie\"}\n\nplt.figure(figsize=(7,6))\nfor cls in np.unique(y):\n    m = (y == cls)\n    plt.scatter(Z[m,0], Z[m,1], s=10, alpha=0.35,\n                c=colors[cls], label=labels[cls], edgecolors=\"none\")\n\n# Optional linear decision line for A vs B\nif drop_ties:\n    lr2d = LogisticRegression(max_iter=2000).fit(Z, y)\n    x_min, x_max = Z[:,0].min()-0.5, Z[:,0].max()+0.5\n    y_min, y_max = Z[:,1].min()-0.5, Z[:,1].max()+0.5\n    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n                         np.linspace(y_min, y_max, 200))\n    zz = lr2d.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n    plt.contour(xx, yy, zz, levels=[0.5], colors=\"k\", linewidths=1.5)\n\nplt.title(\"A vs B separability (TF-IDF → SVD 2D)\" if drop_ties else \"A/B/Tie separability\")\nplt.xlabel(\"SVD component 1\")\nplt.ylabel(\"SVD component 2\")\nplt.legend(markerscale=2, frameon=True)\nplt.tight_layout()\nplt.show()\n\n#Clear gap between red (A) and blue (B) with a mostly straight border → a linear model (logistic regression) on your features should work.\n#Strong mixing/overlap → features aren’t expressive enough; try better text features (embeddings, more n‑grams, char n‑grams) and swap augmentation.\n#If the border would need to bend around blobs → consider nonlinear models (GBM/trees) or richer features.","metadata":{"_uuid":"44418bff-bdf4-4409-b8ed-6ed5069edcec","_cell_guid":"e4c03bc2-23eb-4015-8efb-ad2b6bb38b15","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-08T14:36:51.267690Z","iopub.execute_input":"2025-11-08T14:36:51.267985Z","iopub.status.idle":"2025-11-08T14:37:06.368065Z","shell.execute_reply.started":"2025-11-08T14:36:51.267945Z","shell.execute_reply":"2025-11-08T14:37:06.367084Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"p = df_train[[\"winner_model_a\",\"winner_model_b\",\"winner_tie\"]].mean()\nratio = p.max() / p.min()\nprint(f\"max/min ratio = {ratio:.3f}\")\nprint(\"is_balanced(<1.5):\", ratio < 1.5)","metadata":{"_uuid":"dc987e00-371d-4ad4-b2d5-45ce792c7c9e","_cell_guid":"481a826c-d9ce-40ab-84bd-21446496c7e3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-08T14:37:06.369143Z","iopub.execute_input":"2025-11-08T14:37:06.369502Z","iopub.status.idle":"2025-11-08T14:37:06.378748Z","shell.execute_reply.started":"2025-11-08T14:37:06.369455Z","shell.execute_reply":"2025-11-08T14:37:06.377869Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count model_a\nwin_a = df_train.groupby(\"model_a\")[\"winner_model_a\"].mean()\n\n# Count model_b\nwin_b = df_train.groupby(\"model_b\")[\"winner_model_b\"].mean()\n\n# Concat\nmodel_winrate = pd.concat([win_a, win_b], axis=1).fillna(0)\nmodel_winrate.columns = [\"win_as_A\", \"win_as_B\"]\n\n# total winrate\nmodel_winrate[\"total_winrate\"] = (model_winrate[\"win_as_A\"] + model_winrate[\"win_as_B\"]) / 2\n\n#check position bias\nmodel_winrate[\"bias\"]= abs(model_winrate[\"win_as_A\"] - model_winrate[\"win_as_B\"])\nmodel_winrate.sort_values(\"total_winrate\", ascending=False)","metadata":{"_uuid":"7e2e5dbf-c31b-48b5-838b-ea93e9e5e9ac","_cell_guid":"e26b010f-1583-43e4-9997-c03e2762a3ef","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-08T14:37:06.379760Z","iopub.execute_input":"2025-11-08T14:37:06.380310Z","iopub.status.idle":"2025-11-08T14:37:06.425913Z","shell.execute_reply.started":"2025-11-08T14:37:06.380281Z","shell.execute_reply":"2025-11-08T14:37:06.425058Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preprocess text\ndf_train[\"text\"] = (\"[PROMPT] \" + df_train[\"prompt\"].fillna(\"\").astype(str) +\" [ans_A] \" + df_train[\"response_a\"].fillna(\"\").astype(str) + \" [ans_B] \" + df_train[\"response_b\"].fillna(\"\").astype(str))\n\ndf_test[\"text\"] = (\"[PROMPT] \" + df_test[\"prompt\"].fillna(\"\").astype(str) +\" [ans_A] \" + df_test[\"response_a\"].fillna(\"\").astype(str) +\" [ans_B] \" + df_test[\"response_b\"].fillna(\"\").astype(str))","metadata":{"_uuid":"0b5da85b-3686-4418-b2e2-84d27f031cc1","_cell_guid":"d3278a04-f12a-4d5f-b04a-6e36931997c4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-08T14:37:06.426738Z","iopub.execute_input":"2025-11-08T14:37:06.426966Z","iopub.status.idle":"2025-11-08T14:37:06.707256Z","shell.execute_reply.started":"2025-11-08T14:37:06.426949Z","shell.execute_reply":"2025-11-08T14:37:06.706214Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Targets needs aslo to be in 1d\ny = np.argmax(df_train[[\"winner_model_a\",\"winner_model_b\",\"winner_tie\"]].values, axis=1)","metadata":{"_uuid":"2011e5bb-0587-4752-baec-5d384aa7444a","_cell_guid":"9c9c6eed-f28f-4c21-ae4e-dfbc2c5e53e6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-08T14:37:06.710128Z","iopub.execute_input":"2025-11-08T14:37:06.710398Z","iopub.status.idle":"2025-11-08T14:37:06.717378Z","shell.execute_reply.started":"2025-11-08T14:37:06.710378Z","shell.execute_reply":"2025-11-08T14:37:06.716427Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# original text\norig_text = df_train[\"text\"]\n\n# swapped text (A<->B)\nswap_text = (\n    \"[PROMPT] \" + df_train[\"prompt\"].fillna(\"\").astype(str) +\n    \" [ans_A] \"     + df_train[\"response_b\"].fillna(\"\").astype(str) +\n    \" [ans_B] \"     + df_train[\"response_a\"].fillna(\"\").astype(str)\n)\n\n# swapped labels: A<->B, Tie stays\ny_swap = np.where(y==0, 1, np.where(y==1, 0, 2))\n\n# augment\ntext_aug = pd.concat([orig_text, swap_text], ignore_index=True)\ny_aug = np.concatenate([y, y_swap])","metadata":{"_uuid":"4876710a-6fbc-4c6d-9268-e84746808e63","_cell_guid":"e3ae2cea-4a4e-4b9a-b121-d6f45ec64790","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-08T14:37:06.718353Z","iopub.execute_input":"2025-11-08T14:37:06.718675Z","iopub.status.idle":"2025-11-08T14:37:07.878259Z","shell.execute_reply.started":"2025-11-08T14:37:06.718643Z","shell.execute_reply":"2025-11-08T14:37:07.877219Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vectorizer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nX = df_train[[\"prompt\",\"response_a\",\"response_b\"]].fillna(\"\")\n\nvec = ColumnTransformer(\n    transformers=[\n        # Prompt: words 1–2 help topic/context\n        (\"p_word\", TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.9,\n                                   sublinear_tf=True, max_features=150_000,\n                                   dtype=np.float32), \"prompt\"),\n        # Responses: character n-grams catch phrasing, punctuation, and small errors\n        (\"a_char\", TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3,5),\n                                   min_df=2, max_features=200_000,\n                                   dtype=np.float32), \"response_a\"),\n        (\"b_char\", TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3,5),\n                                   min_df=2, max_features=200_000,\n                                   dtype=np.float32), \"response_b\"),\n    ],\n    sparse_threshold=1.0\n)","metadata":{"_uuid":"a09b1786-b0b4-4f5c-b494-0e5c3e02c2b9","_cell_guid":"263a2aba-3723-4ebb-bb08-70f4ad249858","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-08T14:37:07.879642Z","iopub.execute_input":"2025-11-08T14:37:07.879971Z","iopub.status.idle":"2025-11-08T14:37:08.087203Z","shell.execute_reply.started":"2025-11-08T14:37:07.879945Z","shell.execute_reply":"2025-11-08T14:37:08.086284Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss\nimport numpy as np\n\ny = df_train[[\"winner_model_a\",\"winner_model_b\",\"winner_tie\"]].values.argmax(1)\ntext = (\n    \"[PROMPT] \" + df_train[\"prompt\"].fillna(\"\").astype(str) +\n    \" [ANS_A] \" + df_train[\"response_a\"].fillna(\"\").astype(str) +\n    \" [ANS_B] \" + df_train[\"response_b\"].fillna(\"\").astype(str)\n)\n\n#this value is the trh\nuniform = np.full((len(y), 3), 1/3, dtype=float)\nprint(f\"Baseline loss: {log_loss(y, uniform):.6f}\")\n# Quick settings for speed\n\nclf = LogisticRegression(\n    solver=\"saga\",           # handles large sparse matrices\n    multi_class=\"multinomial\",\n    C=4.0,                   # inverse regularization; tune this\n    max_iter=4000\n)\n\npipe = Pipeline([(\"vec\", vec), (\"clf\", clf)])\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nscores = cross_val_score(pipe, X, y, cv=skf, scoring=\"neg_log_loss\", n_jobs=-1)\nprint(f\"5-fold CV log_loss: {-scores.mean():.4f} ± {scores.std():.4f}\")","metadata":{"_uuid":"e6179762-b0a3-40b4-bf5d-39b74df59c18","_cell_guid":"e7782b0c-2b60-4634-9bda-ea0b091bb53c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-11-08T14:37:08.088280Z","iopub.execute_input":"2025-11-08T14:37:08.088545Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rom sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    \"clf__C\": [0.5, 1, 2, 4, 8],\n    \"vec__p_word__ngram_range\": [(1,1), (1,2)],\n    \"vec__a_char__ngram_range\": [(3,5), (4,6)],\n    \"vec__b_char__ngram_range\": [(3,5), (4,6)],\n    # Optional caps for memory/time:\n    \"vec__p_word__max_features\": [100_000, 150_000],\n    \"vec__a_char__max_features\": [150_000, 200_000],\n    \"vec__b_char__max_features\": [150_000, 200_000],\n}\n\ngrid = GridSearchCV(\n    pipe, param_grid=param_grid, scoring=\"neg_log_loss\",\n    cv=skf, n_jobs=-1, verbose=1\n)\ngrid.fit(X, y)\nprint(\"Best log_loss:\", -grid.best_score_)\nprint(\"Best params:\", grid.best_params_)\nbest_model = grid.best_estimator_","metadata":{"_uuid":"b9a4385e-4ca9-406a-9c08-84fd417e4e14","_cell_guid":"d793b0f3-b763-4d76-82f7-812cbd38150b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import log_loss\nimport numpy as np\nimport pandas as pd\n\nprobs = cross_val_predict(pipe, X, y, cv=skf, method=\"predict_proba\", n_jobs=-1)\nprint(\"OOF log_loss:\", log_loss(y, probs))\n\noof = df_train.copy()\noof[\"y\"] = y\noof[[\"pA\",\"pB\",\"pTie\"]] = probs\noof[\"loss\"] = -np.log(np.take_along_axis(probs, y[:,None], axis=1)).ravel()\noof.sort_values(\"loss\", ascending=False).head(15)[\n    [\"prompt\",\"response_a\",\"response_b\",\"y\",\"pA\",\"pB\",\"pTie\",\"loss\"]\n]","metadata":{"_uuid":"661234df-55b0-4318-b7fa-22b8000a3f7e","_cell_guid":"b9b0eac3-6aac-4482-a470-fe47b7f36a6a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import FunctionTransformer\nfrom sklearn.pipeline import FeatureUnion\nfrom scipy import sparse\n\ndef simple_feats(df):\n    import numpy as np\n    pa = df[\"response_a\"].fillna(\"\")\n    pb = df[\"response_b\"].fillna(\"\")\n    pr = df[\"prompt\"].fillna(\"\")\n    def ov(a, b): return np.array([len(set(a.split()) & set(b.split()))], dtype=float)\n    feats = []\n    for a, b, p in zip(pa, pb, pr):\n        feats.append([\n            len(a), len(b),\n            a.count(\"?\"), b.count(\"?\"),\n            a.count(\"!\"), b.count(\"!\"),\n            len(set(a.split())), len(set(b.split())),\n            len(set(p.split()) & set(a.split())),\n            len(set(p.split()) & set(b.split())),\n        ])\n    return np.array(feats, dtype=float)\n\nnum_feats = FunctionTransformer(simple_feats, validate=False)\n\ncombined = ColumnTransformer(\n    transformers=list(vec.transformers) + [\n        (\"num\", num_feats, [\"prompt\",\"response_a\",\"response_b\"])\n    ],\n    sparse_threshold=1.0\n)\n\npipe2 = Pipeline([(\"vec\", combined), (\"clf\", clf)])\nscores = cross_val_score(pipe2, X, y, cv=skf, scoring=\"neg_log_loss\", n_jobs=-1)\nprint(f\"With simple features, log_loss: {-scores.mean():.4f}\")","metadata":{"_uuid":"20afca58-7371-4402-8796-0077aacd5a61","_cell_guid":"dd27181a-319c-42dd-9578-db81be373966","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_pairwise(df):\n    # yA: 1 if A wins; 0 otherwise\n    yA = (df[\"winner_model_a\"] == 1).astype(int).values\n    yB = (df[\"winner_model_b\"] == 1).astype(int).values\n\n    XA = df[[\"prompt\",\"response_a\"]].rename(columns={\"response_a\":\"response\"})\n    XB = df[[\"prompt\",\"response_b\"]].rename(columns={\"response_b\":\"response\"})\n    X_pair = pd.concat([XA, XB], ignore_index=True)\n    y_pair = np.concatenate([yA, yB])\n    return X_pair, y_pair\n\nX_pair, y_pair = make_pairwise(df_train)\n\nvec_pw = ColumnTransformer([\n    (\"p_word\", TfidfVectorizer(ngram_range=(1,2), min_df=2, sublinear_tf=True), \"prompt\"),\n    (\"r_char\", TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3,5), min_df=2), \"response\"),\n])\n\nclf_pw = LogisticRegression(solver=\"saga\", max_iter=4000)\npipe_pw = Pipeline([(\"vec\", vec_pw), (\"clf\", clf_pw)])\n\nscores = cross_val_score(pipe_pw, X_pair, y_pair, cv=skf, scoring=\"neg_log_loss\", n_jobs=-1)\nprint(\"Pairwise OOF log_loss (binary):\", -scores.mean())","metadata":{"_uuid":"e6fff7d9-9a87-492f-a0a3-ab239f24a7dc","_cell_guid":"114c3b7e-5358-43d6-b30c-dbf7937eddfe","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.ensemble import VotingClassifier\n\nsgd = Pipeline([\n    (\"vec\", vec),\n    (\"clf\", SGDClassifier(loss=\"log_loss\", alpha=1e-4, max_iter=2000, random_state=42))\n])\n\nlr = pipe  # from above\n\n# Calibrate SGD (often underconfident/overconfident)\nsgd_cal = CalibratedClassifierCV(sgd, method=\"isotonic\", cv=3)\n\nvoter = VotingClassifier(\n    estimators=[(\"lr\", lr), (\"sgd\", sgd_cal)],\n    voting=\"soft\", weights=[1,1]\n)\n\nscores = cross_val_score(voter, X, y, cv=skf, scoring=\"neg_log_loss\", n_jobs=-1)\nprint(\"Ensemble log_loss:\", -scores.mean())","metadata":{"_uuid":"43fe38a4-31e7-45bc-b1de-f036bc90e2e0","_cell_guid":"96b0e554-b430-466d-b3d1-24d7b94e2a44","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n# Models\nlog_reg = LogisticRegression(max_iter=2000, class_weight=\"balanced\", C=2.0)\nrf = RandomForestClassifier(n_estimators=300, max_depth=20, n_jobs=-1, random_state=42)\n\nclf = VotingClassifier(estimators=[(\"lr\", log_reg), (\"rf\", rf)],voting=\"soft\")","metadata":{"_uuid":"17ee94d7-2af5-4cad-abe4-d7d74d362846","_cell_guid":"3dbf1c5f-1d8f-4a55-aadd-42bed5ec7486","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train\nX = vectorizer.fit_transform(text_aug)\nclf.fit(X, y_aug)","metadata":{"_uuid":"7dab4f82-19ef-4dc0-9503-76949f7a5bf1","_cell_guid":"6fe5696b-7fa5-45bf-95a3-d1e06f5e6e72","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(X.shape)                         # (n_rows, n_features) e.g., (55000, 5000)\nprint(len(vectorizer.get_feature_names_out()))","metadata":{"_uuid":"2d6acf25-f0b8-4606-a225-5e57dacd3b2d","_cell_guid":"45ab9d6a-638d-47d5-b053-5611cc599b41","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict on test\nX_test = vectorizer.transform(df_test[\"text\"])\nprobs = clf.predict_proba(X_test)","metadata":{"_uuid":"86e062de-a987-4af9-b195-50caa353c9d9","_cell_guid":"4d4c2b83-821f-4a6f-8784-0078554f4d82","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Submission\nsubmission = pd.DataFrame({\n    \"id\": df_test[\"id\"],\n    \"winner_model_a\": probs[:,0],\n    \"winner_model_b\": probs[:,1],\n    \"winner_tie\": probs[:,2],\n})","metadata":{"_uuid":"ba1412a6-c406-431b-aa87-96e79ae9324f","_cell_guid":"8dedca50-d66e-45fc-b6fe-7a34d101a304","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import display\ndisplay(submission.head())","metadata":{"_uuid":"0211ed9b-47d1-4f47-ad47-0f441a326556","_cell_guid":"05c14343-2768-4573-a023-0ceac25fb1e0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)\nprint(\"Submission file created successfully: submission.csv\")","metadata":{"_uuid":"b5192d2d-a82b-4657-821d-96f254e7ae4e","_cell_guid":"f73bc450-a657-4ce6-b102-b51f12890910","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}